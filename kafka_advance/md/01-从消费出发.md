# offset

## 不同Group的offset提交

实际上，同一个Replica Leader可以提交不同Consumer Group的Consumer的offset，这一点和RabbitMQ不同，对于RabbitMQ来说一个Queue的消息被提交后就会被删除，而Replica Leader的消息被提交后，__consumer_offsets只会认为这个Consumer Group已经消费了这条消息，但其他Consumer仍可以消费。打个比方，某个Partition P有10条消息，offset分别从0-9：

![image-20230619124541364](01-从消费出发.assets/01.png)

假设有两个Group 分别为Group G1、Group G2，其中Group G1提交了offset = 4，Group G2提交了offset = 6的消息：

![02](01-从消费出发.assets/02.png)

Consumer直接向Coordinator提交offset，Coordinator将offset提交到_consumer_offsets这个Topic里，以`Consumer Group ID, topicName, Partition ID`格式的Key来区分不同Consumer Group对相同Partition提交的offset。它们在 __consumer_offsets 主题中的记录仍然是独立的，可以区分开来。这样，消费者组 A 和消费者组 B 的 offset 就不会被混淆或互相影响。

当然，消息不会这么一直堆积下去，这会造成磁盘危机，因此需要配合Kafka的消息清除策略管理消息，当Consumer seek一个已被删除的offset会报错。

## offset覆盖

对于同一个Partition、同一个Group而言，上一次被Consumer Pull的消息必须要先Commit，下次Pull才能拿到后面的消息。打个比方，Group A1本次从Partition P pull 了200条消息，offset范围是0-199，要是Group A1下次想Pull到offset >= 200的消息，就必须在本次先commit 199，简答来说就一句话；本次connmit x，下次pull x+n。

值得注意的是，Kafka的offset提交代表提交<=offset的所有消息，可以理解为RabbitMQ的basicAck multiple = true，区别是Kafka不会删除消息，只会标记这个offset之前的消息已经被这个Group消费了，而RabbitMQ会给消息打上删除标记，等待后续进程的删除。也就是说：**当@KafkaListener使用多线程并发消费的时候，要注意commit offset的最终一致性问题，避免低offset的线程比高offset的线程先commit，否则下次会出现重复消费的情况**。

然而在实际使用中，往往消费者是一批一批地pull消息，假设以500为批次pull消息，在业务代码中通常会先处理完这500条消息再手动commit第500条消息的offset，如果第480条消息消费失败，可以先commit第479条消息的offset，**等下次pull的时候再获取到第480条及往后的消息**。

当然，如果因为不可抗力commit了一条在业务上消费失败的数据（假设offset = x）并且想重新消费它，可以通过Consumer的seek(x)方法重新以offset = x为起点消费消息，**当commit了x后__consumer_offsets对于这个Group的已消费offset就会重置为x，所以使用seek后要注意重复消费的问题。**